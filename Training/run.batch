#!/bin/bash

#SBATCH --nodes=1
#SBATCH --cpus-per-task=8
#SBATCH --ntasks-per-node=1
#SBATCH --gres=gpu:1
#SBATCH --time=10:00:00
#SBATCH --account=cs-503
#SBATCH --qos=cs-503
#SBATCH --mem=32GB

# --- Clean environment and load modules FIRST ---
module purge  # Start fresh
module load gcc/11.3.0
module load python

# --- Set CUDA environment ---
export CUDA_HOME=/ssoft/spack/syrah/v2/opt/spack/linux-rhel9-skylake_avx512/gcc-11.3.0/cuda-11.8.0-digmv672nnmhjnm43eg6xagxqaa56igy
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH

# --- Activate virtualenv AFTER loading modules ---
source /work/cvlab/students/bhagavan/SemesterProject/flowbench-tools/.flowbench/bin/activate

# --- Set compiler flags for Python headers ---
# Find Python include path from the loaded module (example path - verify with HPC admins)
export PYTHON_INCLUDE=$(python3 -c "from sysconfig import get_paths; print(get_paths()['include'])")
export CPLUS_INCLUDE_PATH=$PYTHON_INCLUDE:$CPLUS_INCLUDE_PATH  # For C++ compiler

# --- Avoid CUDA arch warnings ---
export TORCH_CUDA_ARCH_LIST="7.0"  # For Tesla V100

# --- Clean previous build cache ---
rm -rf ~/.cache/torch_extensions/py39_cu124/filtered_lrelu_plugin

# --- Debugging ---
echo "===== Environment Diagnostics ====="
echo "Python binary: $(which python3)"
echo "Python version: $(python3 --version)"
echo "CUDA version: $(nvcc --version | grep release)"
echo "Python headers path: $PYTHON_INCLUDE"
echo "==================================="

# --- Run the script ---
srun python3 inference_CNO.py